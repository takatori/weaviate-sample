{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2r0psot1bs3",
   "metadata": {},
   "source": [
    "# MUVERA (ColBERT Multi-Vector) è©•ä¾¡\n",
    "\n",
    "Weaviateã®MUVERAã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ä½¿ç”¨ã—ã¦ColBERTãƒãƒ«ãƒãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®æ€§èƒ½ã‚’è©•ä¾¡ã—ã¾ã™ã€‚\n",
    "\n",
    "- **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**: JQaRA (Japanese Question-Answer Retrieval Assessment)\n",
    "- **ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°**: JaColBERT ã¾ãŸã¯ JaColBERTv2.5 (åˆ‡ã‚Šæ›¿ãˆå¯èƒ½)\n",
    "- **è©•ä¾¡æ–¹å¼**: å„ã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦100ä»¶ã®å€™è£œæ–‡æ›¸ã‚’ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gbs80b1shy5",
   "metadata": {},
   "source": [
    "## 1. ãƒ¢ãƒ‡ãƒ«é¸æŠã¨Weaviateæ¥ç¶š\n",
    "\n",
    "ä½¿ç”¨ã™ã‚‹ColBERTãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¾ã™ã€‚`encoder.py`ã§ç”Ÿæˆã—ãŸã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã¨åŒã˜ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d68d3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: answerdotai/JaColBERTv2.5\n",
      "Collection name: jqara_muvera_jacolbert_v2_5\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "\n",
    "# ---------- ãƒ¢ãƒ‡ãƒ«é¸æŠ ----------\n",
    "# encoder.py ã¨åŒã˜ãƒ¢ãƒ‡ãƒ«å®šç¾©\n",
    "SUPPORTED_MODELS = {\n",
    "    \"jacolbert\": \"bclavie/JaColBERT\",\n",
    "    \"jacolbert-v2.5\": \"answerdotai/JaColBERTv2.5\",\n",
    "}\n",
    "\n",
    "# ã“ã“ã§ãƒ¢ãƒ‡ãƒ«ã‚’åˆ‡ã‚Šæ›¿ãˆï¼ˆencoder.pyã®--modelã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¨åˆã‚ã›ã‚‹ï¼‰\n",
    "# SELECTED_MODEL = \"jacolbert\"  # ã¾ãŸã¯ \"jacolbert-v2.5\"\n",
    "SELECTED_MODEL = \"jacolbert-v2.5\"\n",
    "\n",
    "MODEL_NAME = SUPPORTED_MODELS[SELECTED_MODEL]\n",
    "print(f\"Using model: {MODEL_NAME}\")\n",
    "\n",
    "# Weaviateæ¥ç¶š\n",
    "client = weaviate.connect_to_local()\n",
    "\n",
    "# ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åï¼ˆãƒ¢ãƒ‡ãƒ«ã”ã¨ã«åˆ†ã‘ã‚‹ï¼‰\n",
    "MUVERA_CLASS_NAME = f\"jqara_muvera_{SELECTED_MODEL.replace('-', '_').replace('.', '_')}\"\n",
    "print(f\"Collection name: {MUVERA_CLASS_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3whlgfjxpl",
   "metadata": {},
   "source": [
    "## 2. MUVERAã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆ\n",
    "\n",
    "MUVERAã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ä½¿ç”¨ã—ãŸãƒãƒ«ãƒãƒ™ã‚¯ãƒˆãƒ«ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆã—ã¾ã™ã€‚\n",
    "- `q_id`: ã‚¯ã‚¨ãƒªIDã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœ‰åŠ¹ï¼‰\n",
    "- `multi_vector`: ColBERTã®ãƒˆãƒ¼ã‚¯ãƒ³ãƒ¬ãƒ™ãƒ«ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ ¼ç´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7189189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.config import Configure, Property, DataType\n",
    "\n",
    "if client.collections.exists(MUVERA_CLASS_NAME):\n",
    "    client.collections.delete(MUVERA_CLASS_NAME)\n",
    "\n",
    "client.collections.create(\n",
    "    name=MUVERA_CLASS_NAME,\n",
    "    vector_config=[\n",
    "        Configure.MultiVectors.self_provided(\n",
    "            name=\"multi_vector\",\n",
    "            encoding=Configure.VectorIndex.MultiVector.Encoding.muvera(),\n",
    "        ),\n",
    "    ],\n",
    "    properties=[\n",
    "        Property(name=\"d_id\", data_type=DataType.TEXT),\n",
    "        Property(name=\"q_id\", data_type=DataType.TEXT, index_filterable=True),\n",
    "        Property(name=\"title\", data_type=DataType.TEXT),\n",
    "        Property(name=\"text\", data_type=DataType.TEXT),\n",
    "    ],\n",
    ")\n",
    "\n",
    "muvera_col = client.collections.get(MUVERA_CLASS_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gfjtlz5ymba",
   "metadata": {},
   "source": [
    "## 3. JQaRAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿\n",
    "\n",
    "JQaRAãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚å„ãƒ¬ã‚³ãƒ¼ãƒ‰ã«ã¯ä»¥ä¸‹ãŒå«ã¾ã‚Œã¾ã™ï¼š\n",
    "- `id`: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆID\n",
    "- `q_id`: ã‚¯ã‚¨ãƒªIDï¼ˆåŒä¸€ã‚¯ã‚¨ãƒªã«å¯¾ã™ã‚‹è¤‡æ•°ã®å€™è£œæ–‡æ›¸ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼‰\n",
    "- `label`: æ­£è§£ãƒ©ãƒ™ãƒ«ï¼ˆ1=é–¢é€£, 0=éé–¢é€£ï¼‰\n",
    "- `text`, `title`: æ–‡æ›¸å†…å®¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb92cffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'QA20CAPR-1004#5191928', 'q_id': 'QA20CAPR-1004', 'passage_row_id': '5191928', 'label': 1, 'text': 'çµ¶å¯¾é›¶åº¦(ãœã£ãŸã„ã‚Œã„ã©ã€ã‚¢ãƒ–ã‚½ãƒªãƒ¥ãƒ¼ãƒˆã‚¼ãƒ­ã€è‹±: Absolute zero)ã¯ã€ç†±åŠ›å­¦ä¸Šã®æœ€ä½æ¸©åº¦ã§ã‚ã‚‹æ‘‚æ°âˆ’273.15åº¦ã€‚', 'title': 'çµ¶å¯¾é›¶åº¦ (æ›–æ˜§ã•å›é¿)', 'question': 'æ‘‚æ°ã§ã¯ãƒã‚¤ãƒŠã‚¹273.15åº¦ã«ã‚ãŸã‚‹ã€å…¨ã¦ã®åŸå­ã®æŒ¯å‹•ãŒåœæ­¢ã™ã‚‹æœ€ã‚‚ä½ã„æ¸©åº¦ã‚’ä½•ã¨ã„ã†ã§ã—ã‚‡ã†?', 'answers': ['çµ¶å¯¾é›¶åº¦']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "dataset = []\n",
    "# notebookãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹\n",
    "project_root = Path(os.getcwd()).parent\n",
    "file_path = project_root / \"data\" / \"jqara_test.jsonl\"\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        obj = json.loads(line)        \n",
    "        dataset.append(obj)\n",
    "\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uk51mbgkdx",
   "metadata": {},
   "source": [
    "## 4. ColBERTã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°èª­ã¿è¾¼ã¿\n",
    "\n",
    "`encoder.py`ã§äº‹å‰ç”Ÿæˆã—ãŸColBERTãƒãƒ«ãƒãƒ™ã‚¯ãƒˆãƒ«ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚\n",
    "å„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ `[n_tokens, dim]` å½¢çŠ¶ã®ãƒ†ãƒ³ã‚½ãƒ«ã‚’æŒã¡ã¾ã™ã€‚\n",
    "\n",
    "å‡ºåŠ›ãƒ‘ã‚¹ã¯ `outputs/{model_name}/batch_*.pt` ã®å½¢å¼ã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c086ec42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: jacolbert-v2.5\n",
      "Batches: 326, Docs: 166700\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import torch\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ã«å¯¾å¿œã™ã‚‹ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "embedding_dir = project_root / \"outputs\" / SELECTED_MODEL\n",
    "batch_paths = sorted(glob.glob(str(embedding_dir / \"batch_*.pt\")))\n",
    "\n",
    "if not batch_paths:\n",
    "    raise FileNotFoundError(f\"No batch files found in {embedding_dir}. Run encoder.py first with --model {SELECTED_MODEL}\")\n",
    "\n",
    "ids = []\n",
    "embeddings = []  # List[Tensor[n_tokens, dim]]\n",
    "\n",
    "for p in batch_paths:\n",
    "    payload = torch.load(p, map_location=\"cpu\")\n",
    "    ids.extend([str(x) for x in payload.get(\"ids\", [])])\n",
    "    for e in payload.get(\"embeddings\", []):\n",
    "        if isinstance(e, torch.Tensor):\n",
    "            embeddings.append(e.detach().to(\"cpu\").contiguous())\n",
    "        else:\n",
    "            embeddings.append(torch.as_tensor(e, dtype=torch.float32))\n",
    "\n",
    "assert len(ids) == len(embeddings)\n",
    "\n",
    "print(f\"Model: {SELECTED_MODEL}\")\n",
    "print(f\"Batches: {len(batch_paths)}, Docs: {len(embeddings)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gkojiypac3d",
   "metadata": {},
   "source": [
    "## 5. Weaviateã¸ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "\n",
    "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨ColBERTã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’MUVERAã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã«ãƒãƒƒãƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00703c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“¤ Uploading to Weaviate: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166700/166700 [06:47<00:00, 409.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… All objects uploaded successfully!\n",
      "ğŸ§® ç¾åœ¨ã®ç™»éŒ²ä»¶æ•°: 166700\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "N = 166700\n",
    "subset = dataset[:N]\n",
    "emb_subset = embeddings[:N]\n",
    "\n",
    "total = len(subset)\n",
    "\n",
    "with muvera_col.batch.fixed_size(batch_size=16) as batch, tqdm(total=total, desc=\"ğŸ“¤ Uploading to Weaviate\") as pbar:\n",
    "    for obj, emb in zip(subset, emb_subset):\n",
    "        batch.add_object(\n",
    "            properties={\n",
    "                \"d_id\": obj[\"id\"],\n",
    "                \"q_id\": obj[\"q_id\"],\n",
    "                \"text\": obj[\"text\"],\n",
    "                \"title\": obj[\"title\"],\n",
    "            },\n",
    "            vector={\"multi_vector\": emb.tolist()},\n",
    "        )\n",
    "        pbar.update(1)\n",
    "\n",
    "if muvera_col.batch.failed_objects:\n",
    "    print(f\"\\nâŒ Number of failed imports: {len(muvera_col.batch.failed_objects)}\")\n",
    "    print(f\"First failed object: {muvera_col.batch.failed_objects[0]}\")\n",
    "else:\n",
    "    print(\"\\nâœ… All objects uploaded successfully!\")\n",
    "\n",
    "count = muvera_col.aggregate.over_all(total_count=True).total_count\n",
    "print(f\"ğŸ§® ç¾åœ¨ã®ç™»éŒ²ä»¶æ•°: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k7dn5zpd4a",
   "metadata": {},
   "source": [
    "## 6. ColBERTãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿\n",
    "\n",
    "ã‚¯ã‚¨ãƒªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ç”¨ã«ColBERTãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚é¸æŠã—ãŸãƒ¢ãƒ‡ãƒ«ã¨åŒã˜ã‚‚ã®ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "scitvk6x46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoshi.takatori.001/Desktop/playground/weaviate-sample/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "<frozen importlib._bootstrap>:488: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute\n",
      "<frozen importlib._bootstrap>:488: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute\n",
      "<frozen importlib._bootstrap>:488: DeprecationWarning: builtin type swigvarlink has no __module__ attribute\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint: answerdotai/JaColBERTv2.5\n",
      "[Dec 24, 09:02:51] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoshi.takatori.001/Desktop/playground/weaviate-sample/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler()\n",
      "/Users/satoshi.takatori.001/Desktop/playground/weaviate-sample/.venv/lib/python3.12/site-packages/torch/cuda/amp/grad_scaler.py:31: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "from colbert.infra import ColBERTConfig\n",
    "from colbert.modeling.checkpoint import Checkpoint\n",
    "\n",
    "print(f\"Loading checkpoint: {MODEL_NAME}\")\n",
    "ckpt = Checkpoint(MODEL_NAME, colbert_config=ColBERTConfig())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3mjihfax3tx",
   "metadata": {},
   "source": [
    "## 7. è©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿æ§‹é€ ä½œæˆ\n",
    "\n",
    "ranxè©•ä¾¡ç”¨ã®qrelsï¼ˆæ­£è§£ãƒ©ãƒ™ãƒ«ï¼‰ã¨qid_to_queryï¼ˆã‚¯ã‚¨ãƒªãƒãƒƒãƒ”ãƒ³ã‚°ï¼‰ã‚’ä½œæˆã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1626492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 166700 records\n",
      "Unique queries: 1667\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Tuple, Iterable\n",
    "\n",
    "\n",
    "qid_to_query: Dict[str, str] = {}\n",
    "qrels: Dict[str, Dict[str, int]] = {}\n",
    "\n",
    "cnt = 0\n",
    "for rec in subset:\n",
    "    cnt += 1\n",
    "    qid   = rec[\"q_id\"]\n",
    "    q = rec.get(\"question\")\n",
    "    docid = rec.get(\"id\")\n",
    "    rel   = int(rec.get(\"label\", 0))\n",
    "\n",
    "    if qid not in qid_to_query:\n",
    "        qid_to_query[qid] = q\n",
    "    qrels.setdefault(qid, {})[docid] = rel\n",
    "\n",
    "print(f\"Loaded {cnt} records\")\n",
    "print(f\"Unique queries: {len(qid_to_query)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ncl5g8bn23",
   "metadata": {},
   "source": [
    "## 8. éåŒæœŸæ¤œç´¢ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°\n",
    "\n",
    "å…¨ã‚¯ã‚¨ãƒªã‚’ä¸¦åˆ—å®Ÿè¡Œã—ã¦run_dictï¼ˆæ¤œç´¢çµæœï¼‰ã¨ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚’åé›†ã™ã‚‹é–¢æ•°ã‚’å®šç¾©ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1a1bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Awaitable, List, Tuple, Dict\n",
    "import asyncio\n",
    "\n",
    "async def build_run_dict_async_with_qid(\n",
    "        search_fn: Callable[[str, str, int], Awaitable[Tuple[List[Tuple[str, float]], float]]],\n",
    "        qid_to_query: Dict[str, str],\n",
    "        topk: int = 100\n",
    "    ) -> Tuple[Dict[str, Dict[str, float]], List[float]]:\n",
    "    \"\"\"\n",
    "    éåŒæœŸæ¤œç´¢é–¢æ•°ã‚’ä½¿ã£ã¦å…¨ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã—ã€run_dictã¨latenciesã‚’è¿”ã™ã€‚\n",
    "    q_idã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€‚\n",
    "    \n",
    "    Args:\n",
    "        search_fn: (q, q_id, topk) -> ([(doc_id, score), ...], elapsed)\n",
    "        qid_to_query: {qid: query_text} ã®è¾æ›¸\n",
    "        topk: å„ã‚¯ã‚¨ãƒªã§å–å¾—ã™ã‚‹ä»¶æ•°\n",
    "        \n",
    "    Returns:\n",
    "        run_dict: {qid: {doc_id: score, ...}, ...}\n",
    "        latencies: å„ã‚¯ã‚¨ãƒªã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒªã‚¹ãƒˆ\n",
    "    \"\"\"\n",
    "    CONCURRENCY = 10\n",
    "    sem = asyncio.Semaphore(CONCURRENCY)    \n",
    "    run_dict: Dict[str, Dict[str, float]] = {}\n",
    "    latencies: List[float] = []\n",
    "\n",
    "    async def _one(qid: str, q: str):\n",
    "        async with sem:\n",
    "            ranked, elapsed = await search_fn(q, qid, topk)\n",
    "            return qid, ranked, elapsed\n",
    "\n",
    "    tasks = [_one(qid, q) for qid, q in qid_to_query.items()]\n",
    "    \n",
    "    for coro in tqdm(asyncio.as_completed(tasks), total=len(tasks), desc=\"Searching\"):\n",
    "        qid, ranked, elapsed = await coro\n",
    "        run_dict[qid] = {doc_id: score for doc_id, score in ranked}\n",
    "        latencies.append(elapsed)\n",
    "    \n",
    "    return run_dict, latencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olo8st8yn1b",
   "metadata": {},
   "source": [
    "## 9. MUVERAæ¤œç´¢é–¢æ•°\n",
    "\n",
    "q_idã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¦ColBERTãƒãƒ«ãƒãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚’å®Ÿè¡Œã™ã‚‹é–¢æ•°ã‚’å®šç¾©ã—ã¾ã™ã€‚\n",
    "- ã‚¯ã‚¨ãƒªã‚’ColBERTã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰\n",
    "- è©²å½“q_idã®å€™è£œæ–‡æ›¸ç¾¤å†…ã§near_vectoræ¤œç´¢\n",
    "- distanceã‚’åè»¢ã—ã¦ã‚¹ã‚³ã‚¢åŒ–ï¼ˆranxã¯å¤§ãã„ã‚¹ã‚³ã‚¢ã‚’ä¸Šä½ã¨ã™ã‚‹ãŸã‚ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1e12c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from weaviate.classes.query import MetadataQuery, Filter\n",
    "import time\n",
    "\n",
    "async def async_muvera_search(async_col, q: str, q_id: str, topk: int = 100) -> Tuple[List[Tuple[str, float]], float]:\n",
    "    \"\"\"\n",
    "    ColBERT (Multi-vector) ã‚’ç”¨ã„ãŸéåŒæœŸæ¤œç´¢é–¢æ•°\n",
    "    q_idã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¦ã€è©²å½“ã‚¯ã‚¨ãƒªã®å€™è£œæ–‡æ›¸ç¾¤ã®ä¸­ã‹ã‚‰ãƒ©ãƒ³ã‚­ãƒ³ã‚°\n",
    "    \n",
    "    Args:\n",
    "        async_col: éåŒæœŸWeaviateã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³\n",
    "        q: æ¤œç´¢ã‚¯ã‚¨ãƒªæ–‡å­—åˆ—\n",
    "        q_id: ãƒ•ã‚£ãƒ«ã‚¿ç”¨ã®ã‚¯ã‚¨ãƒªID\n",
    "        topk: å–å¾—ã™ã‚‹ä»¶æ•°\n",
    "        \n",
    "    Returns:\n",
    "        ([(doc_id, score), ...], elapsed) ã®ã‚¿ãƒ—ãƒ«\n",
    "        scoreã¯å¤§ãã„ã»ã©è‰¯ã„ï¼ˆdistanceã‚’åè»¢ï¼‰\n",
    "    \"\"\"\n",
    "    # ã‚¯ã‚¨ãƒªã®ãƒ™ã‚¯ãƒˆãƒ«åŒ– (ColBERT)\n",
    "    q_vecs_tensor = ckpt.queryFromText([q], bsize=1)[0]\n",
    "    q_vecs = q_vecs_tensor.tolist()\n",
    "\n",
    "    # éåŒæœŸã‚¯ã‚¨ãƒªã®å®Ÿè¡Œï¼ˆq_idã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    response = await async_col.query.near_vector(\n",
    "        near_vector=q_vecs,\n",
    "        target_vector=\"multi_vector\",\n",
    "        limit=topk,\n",
    "        filters=Filter.by_property(\"q_id\").equal(q_id),\n",
    "        return_metadata=MetadataQuery(distance=True)\n",
    "    )\n",
    "\n",
    "    elapsed = time.perf_counter() - start\n",
    "\n",
    "    # çµæœã®æ•´å½¢: (doc_id, score) ã®ãƒªã‚¹ãƒˆ\n",
    "    # ranxã¯å¤§ãã„ã‚¹ã‚³ã‚¢ã‚’ä¸Šä½ã¨ã™ã‚‹ãŸã‚ã€distanceã‚’åè»¢ï¼ˆè² ã«ã™ã‚‹ï¼‰\n",
    "    results: List[Tuple[str, float]] = []\n",
    "    for obj in response.objects:\n",
    "        doc_id = obj.properties.get(\"d_id\", \"\")\n",
    "        score = -obj.metadata.distance  # è·é›¢ã‚’åè»¢ï¼\n",
    "        results.append((doc_id, score))\n",
    "\n",
    "    return results, elapsed\n",
    "\n",
    "\n",
    "def create_muvera_search_fn(async_col):\n",
    "    \"\"\"async_colã‚’ãƒã‚¤ãƒ³ãƒ‰ã—ãŸæ¤œç´¢é–¢æ•°ã‚’è¿”ã™ãƒ•ã‚¡ã‚¯ãƒˆãƒªï¼ˆq_idå¯¾å¿œç‰ˆï¼‰\"\"\"\n",
    "    async def search_fn(q: str, q_id: str, topk: int = 100) -> Tuple[List[Tuple[str, float]], float]:\n",
    "        return await async_muvera_search(async_col, q, q_id, topk)\n",
    "    return search_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synk1tvokjc",
   "metadata": {},
   "source": [
    "## 10. å…¨ã‚¯ã‚¨ãƒªã§æ¤œç´¢å®Ÿè¡Œ\n",
    "\n",
    "1667ã‚¯ã‚¨ãƒªã™ã¹ã¦ã«å¯¾ã—ã¦MUVERAæ¤œç´¢ã‚’å®Ÿè¡Œã—ã€çµæœã¨ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚’åé›†ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f53htcdm58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching:   0%|          | 0/1667 [00:00<?, ?it/s]/Users/satoshi.takatori.001/Desktop/playground/weaviate-sample/.venv/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
      "/Users/satoshi.takatori.001/Desktop/playground/weaviate-sample/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Searching: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1667/1667 [00:45<00:00, 36.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ¤œç´¢å®Œäº†: 1667 ã‚¯ã‚¨ãƒª\n",
      "å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: 0.1906 ç§’\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# build_run_dict_async_with_qid ã‚’ä½¿ã£ã¦å…¨ã‚¯ã‚¨ãƒªã‚’æ¤œç´¢ï¼ˆq_idãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ç‰ˆï¼‰\n",
    "\n",
    "muvera_search_run_dict = {}\n",
    "muvera_search_latencies = []\n",
    "\n",
    "async with weaviate.use_async_with_local() as async_client:\n",
    "    async_col = async_client.collections.get(MUVERA_CLASS_NAME)\n",
    "    \n",
    "    # async_col ã‚’ãƒã‚¤ãƒ³ãƒ‰ã—ãŸæ¤œç´¢é–¢æ•°ã‚’ä½œæˆ\n",
    "    search_fn = create_muvera_search_fn(async_col)\n",
    "    \n",
    "    # å…¨ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œï¼ˆq_idã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰\n",
    "    muvera_search_run_dict, muvera_search_latencies = await build_run_dict_async_with_qid(\n",
    "        search_fn, \n",
    "        qid_to_query,\n",
    "        topk=100  # å„q_idã«å¯¾å¿œã™ã‚‹å…¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—\n",
    "    )\n",
    "\n",
    "print(f\"æ¤œç´¢å®Œäº†: {len(muvera_search_run_dict)} ã‚¯ã‚¨ãƒª\")\n",
    "print(f\"å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: {sum(muvera_search_latencies) / len(muvera_search_latencies):.4f} ç§’\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kn3bkgt8ie",
   "metadata": {},
   "source": [
    "## 11. è©•ä¾¡é–¢æ•°å®šç¾©\n",
    "\n",
    "ranxã‚’ä½¿ç”¨ã—ã¦NDCG, MAP, MRR, Precision, Recallã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°ã‚’å®šç¾©ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14f51f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ranx import Qrels, Run, evaluate\n",
    "\n",
    "def evaluate_run_dict(run_dict: Dict[str, Dict[str, float]], qrels: Dict[str, Dict[str, int]]):\n",
    "    qrels_ranx = Qrels(qrels)\n",
    "    run_ranx   = Run(run_dict)\n",
    "\n",
    "    metrics = [\n",
    "        \"ndcg@1\", \"ndcg@3\", \"ndcg@5\", \"ndcg@10\",\n",
    "        \"map\", \"mrr\", \"mrr@10\", \"precision@10\", \"recall@10\", \"recall@100\",\n",
    "    ]\n",
    "\n",
    "    scores = evaluate(qrels_ranx, run_ranx, metrics=metrics)\n",
    "    for m in metrics:\n",
    "        print(f\"{m:>12}: {scores[m]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x86s3jq541e",
   "metadata": {},
   "source": [
    "## 12. ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·çµ±è¨ˆé–¢æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81f95c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def print_latency_stats(latencies: List[float]):\n",
    "    l = np.array(latencies)\n",
    "\n",
    "    print(f\"Count    : {len(l)}\")\n",
    "    print(f\"Mean     : {l.mean():.4f} sec\")\n",
    "    print(f\"Median   : {np.median(l):.4f} sec\")\n",
    "    print(f\"p90      : {np.percentile(l,90):.4f} sec\")\n",
    "    print(f\"p95      : {np.percentile(l,95):.4f} sec\")\n",
    "    print(f\"p99      : {np.percentile(l,99):.4f} sec\")\n",
    "    print(f\"Min/Max  : {l.min():.4f} / {l.max():.4f} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3431ehcstv",
   "metadata": {},
   "source": [
    "## 13. è©•ä¾¡çµæœ\n",
    "\n",
    "MUVERAæ¤œç´¢ã®ç²¾åº¦ã¨ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "affb96c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ndcg@1: 0.7822\n",
      "      ndcg@3: 0.6860\n",
      "      ndcg@5: 0.6417\n",
      "     ndcg@10: 0.6176\n",
      "         map: 0.5408\n",
      "         mrr: 0.8501\n",
      "      mrr@10: 0.8480\n",
      "precision@10: 0.4096\n",
      "   recall@10: 0.5117\n",
      "  recall@100: 1.0000\n",
      "Count    : 1667\n",
      "Mean     : 0.1906 sec\n",
      "Median   : 0.1839 sec\n",
      "p90      : 0.2517 sec\n",
      "p95      : 0.2843 sec\n",
      "p99      : 0.3987 sec\n",
      "Min/Max  : 0.0662 / 0.6184 sec\n"
     ]
    }
   ],
   "source": [
    "evaluate_run_dict(muvera_search_run_dict, qrels)\n",
    "print_latency_stats(muvera_search_latencies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
