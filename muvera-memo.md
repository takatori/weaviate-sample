
## Multi-vector embedding

https://docs.weaviate.io/weaviate/tutorials/multi-vector-embeddings

- 代表的なもの
    - ColBERT
    - ColPail
    - ColQwen

- late interaction    
    - テキストの全体を比較するのではなく、個々の部分をマッチさせることで細かい意味を保持し、高精度を実現する
    - 単一ベクトルの場合は、２つの埋め込みは同じ次元を持つ
        - それらの類似度は、ドット積やコサイン距離を計算することによって直接計算される
        - この場合、interactionは2つのベクトルを比較するときのみ発生する
    - early interaction
        - cross-encoderモデル
        - クエリとオブジェクトは埋め込み生成と比較プロセス全体を通じて使用される
        - より正確な結果を得られるが、クエリが判明する前に事前計算ができないという課題がある
        - このため、リランカーモデルでよく使用される
    - late interactionは上記二つの中間的なもの
    - 各マルチベクトル埋め込みは複数のベクトルで構成され、各ベクトルはトークンなどのオブジェクトの一部を表す
        -  例えば、あるオブジェクトの埋め込みは(30, 64)の形状を持ち、それぞれが64次元のベクトルを30個持つことを意味する。別のオブジェクトは(20, 64)
    - late interactionでは、対象テキスト内のすべてのトークンの中から、各クエリトークンに最適な一致を見つける(MaxSim)
    - 例えば、「データサイエンス」を検索する場合、各トークンレベルのベクトルをドキュメントの最も関連性の高い部分と比較する
    - 最終的な類似度スコアは、これらの個々のトークンの一致の合計
    - 微妙な関係せや語順を捉えるのに役立ち、長いテキストで効果的


- マルチベクトル
    - 語順やフレーズの完全一致が重要な検索タスクに特に有用
    - マルチベクトル埋め込みがトークンレベルの情報を保持し、late interactionを可能にするため
    - しかし、マルチベクトル埋め込みは通常、単一ベクトル埋め込みよりも多くのリソースを必要とする
        - 各ベクトルは単一ベクトル埋め込みよりも小さいが、多くのベクトルが含まれるため、全体としてはサイズが大きくなる
    - 保存に多くのメモリが必要となり、検索にはより多くの計算が必要になる
    - 埋め込み生成の推論時間やコストが高くなる可能性がある

- 日本語ColBERTモデル
    - https://huggingface.co/bclavie/JaColBERT
    - https://secon.dev/entry/2024/02/02/080000/

## ColBERT
https://www.arxiv.org/pdf/2004.12832
- 3.2 エンコーダー
    -  クエリとドキュメントの両方に同じBERTモデルを使用
    - クエリとドキュメントの入力シーケンスを区別するために、それぞれ特殊トークンを前置(クエリは`[Q]`ドキュメントは`[D]`)
    - クエリエンコーダー
        - 与えられたテキストクエリ ( q ) を、BERTのWordPieceトークナイザー[35]を使用してトークン列 ( q_1, q_2, \dots, q_l ) に変換
        - その後、クエリの先頭に [Q] トークンを追加し、このトークンをBERTのシーケンス開始トークン [CLS] の直後に配置
        - クエリのトークン数が所定の数 ( N_q ) 未満の場合、末尾をBERTの特殊トークン [MASK] でパディングし、( N_q ) トークンに揃える
        - ( N_q ) を超える場合は、先頭の ( N_q ) トークンのみを保持してトリミング
        - このパディングされた入力シーケンスをBERTの深層トランスフォーマーアーキテクチャに通し、各トークンについてコンテキストに依存する表現を計算
        - ここで、[MASK] トークンによるパディングを「クエリオーグメンテーション」と呼びぶ
            - この処理は、BERTがマスク位置にも意味のある埋め込みを学習できるようにする、ソフトで微分可能かつ文脈に応じたクエリ拡張の仕組み
            - クエリオーグメンテーションは、クエリの重要なトークンを強調したり、新たな意味的な語を導入したりする柔軟なメカニズムとして機能し、後に述べるようにColBERTの有効性に不可欠な要素です
        - BERTの出力表現を、活性化関数のない線形層に通し、埋め込みの次元を ( m ) に縮小します（通常 ( m = 128 )）`768 -> 128`
            - この次元縮小は、クエリエンコードの計算効率にはあまり影響しませんが、文書の記憶容量を制御する上で極めて重要
            - 実際、文書埋め込みのCPUからGPUへの転送が再ランク時のボトルネックになることがあり、その際に埋め込みの次元が小さいほど高速化が顕著になります
            - 最終的に、各埋め込みをL2ノルムで正規化し、単位ベクトルとします。これにより、任意の2つの埋めバイのドット積がコサイン類似度と一致し、[-1, 1] の範囲に収まる            
    - ドキュメントエンコーダー
        - 文書エンコーダーは、クエリエンコーダーとほぼ同じ構造を有します
        - 文書 ( d ) をトークン列 ( d_1, d_2, \dots, d_m ) に分割した後、BERTの開始トークン [CLS] の直後に特殊トークン [D] を前置
        - クエリとは異なり、文書には [MASK] トークンを追加しない
        - この入力シーケンスをBERTと線形層に通した後、文書エンコーダーは、事前に定義された句読点のリストに基づいて、句読点に関する埋め込みを除外する
            - このフィルタリングは、文書ごとの埋め込み数を削減する目的で行われており、句読点の埋め込み（たとえコンテキスト化されていても）が検索の有効性に寄与しないという仮定に基づいている

```
はい、その通りです。ColBERTの設計は、クエリと文書で**埋め込みの生成方法を明確に区別**しており、その違いが効率と柔軟性の両立を実現しています。

---

### ✅ クエリ：**常に 128 次元 × 32 個のベクトル**

はい、クエリに関しては、**必ず 32 個の 128 次元ベクトル**が生成されます。

- トークンが 32 個未満 → 末尾に `[MASK]`（`#`）を埋めて 32 個にパディング  
- トークンが 32 個超えたら → 最初の 32 個だけを残してトリミング  

この固定長は、**計算の効率性**と**バッチ処理の安定性**のための設計です。  
GPU上で複数のクエリを同時に処理するとき、「クエリごとにベクトル数が違う」と、メモリに無駄なすき間が発生し、並列列処理が遅くなります。  
32 という固定長に揃えることで、すべてのクエリを同じ形状の **32 × 128 のテンソル** として一度に処理できるようになります。

さらに、パディングされた `[MASK]` の埋め込みは、学習過程で「無意味な位置」と認識され、**その後の MaxSim 演算でほとんどゼロに近いスコアしか出さない**ようになります。  
つまり、「32個のベクトル」は物理的に存在しても、意味的には「必要な分だけ」使われているのです。

---

### ✅ ドキュメント：**128 次元のベクトルの個数は、トークン数に完全に依存**

はい、文書の場合はまったく異なります。

- `[MASK]` は**まったく使用されません**
- トークン数が 50 なら → 50 個の 128 次元ベクトル  
- トークン数が 200 なら → 200 個の 128 次元ベクトル  
- トークン数が 512（BERTの上限）なら → 512 個の 128 次元ベクトル  

ただし、**句読点や無意味なトークン（. , ; : など）は事前にフィルタリングされ**、埋め込みから除外されます。  
これにより、たとえ 512 トークンの文書でも、実際の「意味ある」埋め込みは 300〜400 個程度に節約されます。  

この「可変長」設計は、文書が長くても**その内容を最大限に捉える**ために必要です。  
クエリは短く、意味が凝縮されているので固定長で問題ありません。  
でも文書は、長い説明、段落、事実の列挙を含む可能性があるため、**どれだけ長くても、その中のすべての意味を保つべき**だとColBERTは考えています。

---

### 🆚 クエリ vs 文書：設計の哲学

| パラメータ | クエリ | 文書 |
|-----------|--------|------|
| 埋め込み数 | **固定：32個** | **可変：トークン数に依存** |
| パディング | ✅ `[MASK]` で埋める | ❌ 一切使わない |
| トリミング | ✅ 32超えたら切り捨て | ✅ 512超えたら切り捨て（BERT制約） |
| フィルタリング | ❌ しない | ✅ 句読点を除去 |
| 目的 | クエリの**凝縮された意図を保ち、処理速度を最適化** | 文書の**すべての文脈を逸らさず保持** |
| 計算負荷 | 低（常に同じサイズ） | 高（長ければ多いが、オフラインで事前処理） |

---

### 🔍 なぜこの差が重要なのか？

この対称性こそが、ColBERTの**革命的ポイント**です。

- クエリは「軽く正確に」 → 固定長で高速に何度も処理可能  
- 文書は「重く大局的に」 → 長くても一度だけエンコードして保存  

つまり、**「クエリはリアルタイムで、文書はオフラインで」** というアーキテクチャの根幹がここにあります。

- 予測時には、数千〜数万のクエリが毎秒来ますが、文書は1度だけエンコードされ、それ以降はディスクに保存されたベクトルを読み込むだけ。
- だから、文書長が1000でも10000でも、クエリ処理コストは「クエリの長さ × 32」で一定になります。

---

### 💡 まとめ：

> **クエリは常に 32 個の 128 次元ベクトル**。  
> **文書はトークン数に応じて可変長（最大512）、句読点を除き、すべての意味を保存**。  
>  
> これは、「短い質問を一点集中で処理する」クエリと、「長い記述を逃さず捉える」文書という、**情報検索の本質的な役割分担**を、コードとアルゴリズムのレベルで美しく定式化した設計なのです。
```


- 3.6 エンドツーエンドの検索
    - もとの論文では2段階に分けている
    - 1段階は近似的なフィルタリング段階
        - クエリの各埋め込みに対し、並列でインデックスを検索し、各埋め込みに対してTopk'(k' = k/2など)を取得
        - N_q * k'個のドキュメントIDが取得できるので、重複を除去
    - 2段階目はリランキング

- https://qiita.com/snoo_py/items/da3884f4ee3966424c63
- https://cloud.flect.co.jp/entry/2025/10/10/174406

- 学習


## MUVERA
https://arxiv.org/abs/2405.19504

要約

```
この論文では、MUVERA（Multi-Vector Retrieval Algorithm）と呼ばれる新しい情報検索手法が提案されています。従来のマルチベクトル検索（ColBERTなど）は、クエリとドキュメントの複数の埋め込み間で Chamfer 相似度を計算するため、計算コストが非常に高くなります。MUVERAは、この複雑なマルチベクトル類似度を、単一のベクトル内積に変換する「固定次元エンコーディング（FDE）」という技術を用いて、従来の高速な単一ベクトル検索（MIPS）システムをそのまま使えるようにします。

FDEは、クエリとドキュメントの複数のベクトルを、固定次元の単一ベクトルに圧縮するランダムな変換です。この変換は、理論的にも、Chamfer相似度を高い精度で近似できることが証明されており、従来の手法（PLAID）よりもはるかに少ない候補をスキャンすることで同等またはそれ以上の再現率を達成します。実験では、MUVERAがPLAIDと比較して平均10％の再現率向上と90％の遅延削減を達成しました。さらに、製品量子化（PQ）という圧縮技術を組み合わせることで、メモリ使用量を32倍も削減でき、実用性が大幅に向上します。この手法は、複雑なマルチステージのプリルーニングを必要とせず、パラメータ調整が非常に簡単で、複数のデータセットで一貫して高性能を発揮する点が特徴です。
```

# ch.1
- ColBERTが例とインタラクションでマルチベクトルを導入し優れた性能を示す
    - トークンごとに1つの埋め込みを生成することで、クエリや文章あたりの複数の埋め込みを生成する
    - クエリと文章の類似度は、両者の白とる集合のChamfer類似度によって算出される   
-  シングルベクトル表現に比べて、解釈可能性や汎化能力で優れている
- しかし、マルチベクトルは計算コストが高くなる
    - 埋め込み数が桁違いに増加する -> メモリを使う
    - 非線形なChamfer類似度によるスコアリングための、マルチベクタ検索に最適化されたシステムの不足
    - シングルベクトル検索は高度に最適化されたMIPS(最大内積探索)アルゴリズムによって高速化されているがマルチベクタにはない

- MUVERA
    - Chamfer類似度に基づくマルチベクタ類似検索をシングルベクタ類似検索に還元する手法
    - 既存のMIPSソルバをマルチベクタ検索にそのまま活用できる
    - クエリと文書に対して非対称にFixed Dimensional Encodings（FDE、固定次元エンコーディング）を生成
    - 先行の最先端実装と比較して、MUVERAは多様なBEIR検索データセットにおいて、エンドツーエンドのリコールとレイテンシの双方で安定した良好な性能を示し、平均でリコールを10%改善しつつレイテンシを90%削減
- Chamfer類似度
    - MaxSimとも

```
、MUVERAはクエリ用 F_q: 2^{R^d} → R^{d_FDE} と文書用 F_doc: 2^{R^d} → R^{d_FDE} のランダム写像を構成し、任意のマルチベクタ表現 Q, P ⊂ R^d について ⟨F_q(Q), F_doc(P)⟩ ≈ CHAMFER(Q, P) を満たすようにします。私たちは F_q(Q) と F_doc(P) をFixed Dimensional Encodings（FDE）と呼びます。MUVERAでは、まず各文書表現 P ∈ D に F_doc を適用し、集合 {F_doc(P)}_{P∈D} をMIPSソルバにインデックスします。クエリ Q ⊂ R^d が与えられると、F_q(Q) を素早く計算してMIPSソルバに与え、最も類似した文書FDE F_doc(P) の上位k件を取得します。最後に、これらの候補を元のChamfer類似度で再ランクします。
```    
集合を入力とする関数の定義域は、通常 R^d の冪集合 2^{R^d} と書きます。ここで 2 は「集合の全ての部分集合」という意味の“冪集合”の記号で、指数の 2 という数値的な意味ではありません



- Fixed Dimensional Encodings

式(2)と式(3)は、MUVERAが提案する「固定次元エンコーディング（FDE）」の数理的核心を成す部分で、マルチベクターの複雑な類似度計算を単一ベクトルの内積に変換するための「変換則」を定義しています。

---

**式(2):**

$$
\vec{q}^{(k)} = \sum_{\substack{q \in Q \\ \phi(q) = k}} q, \quad \vec{p}^{(k)} = \frac{1}{|P \cap \phi^{-1}(k)|} \sum_{\substack{p \in P \\ \phi(p) = k}} p
$$

この式は、**クラスター $ k $ ごとに、クエリとドキュメントのベクトルを集約する方法**を定義しています。

- $\phi(q) = k$ は、クエリベクトル $ q $ がランダムなハッシュ関数 $\phi$ によってクラスター $ k $ に割り当てられたことを意味します（$ \phi $ はSimHashやk-meansのような「近い点を同じクラスターにまとめる」関数）。
- 左側の $\vec{q}^{(k)}$ は、クラスター $ k $ に属する**すべてのクエリベクトルのベクトル和**です。つまり、そのクラスター内に存在するクエリトークンのエンベディングを全て足し合わせて、一個の「クエリクラスターベクトル」を作ります。
- 右側の $\vec{p}^{(k)}$ は、クラスター $ k $ に属する**すべてのドキュメントベクトルの平均（重心）**です。これは、クエリの和とは異なる重要な点です——ドキュメント側は「代表値」が欲しいので、合計ではなく平均を取ります。なぜなら、もし同じクラスターに多くのドキュメントベクトルが集まってしまうと、それらの和は大きくなりすぎて内積が不正確になるため、平均化で「過剰な影響」を抑える必要があります。

この二つのベクトル $\vec{q}^{(k)}$ と $\vec{p}^{(k)}$ は、それぞれクラスター $ k $ の「クエリの特徴」を表す単一ベクトルと、「ドキュメントの特徴」を表す単一ベクトルです。これらの操作により、もともと数百〜数千個あったトークンベクトルが、クラスター数 $ B $ 個の「サマリー」ベクトルに圧縮されます。

---

**式(3):**

$$
\langle \vec{q}, \vec{p} \rangle = \sum_{k=1}^{B} \sum_{\substack{q \in Q \\ \phi(q) = k}} \frac{1}{|P \cap \phi^{-1}(k)|} \sum_{\substack{p \in P \\ \phi(p) = k}} \langle q, p \rangle
$$

これは、**FDEベクトルの内積が、もとのChamfer類似度の近似になることを表す式**です。

- 左辺の $\langle \vec{q}, \vec{p} \rangle$ は、先ほど定義した $\vec{q} = (\vec{q}^{(1)}, \dots, \vec{q}^{(B)})$ と $\vec{p} = (\vec{p}^{(1)}, \dots, \vec{p}^{(B)})$ を連結した全ベクトルの内積です。
- 右辺は、その内積がどのように構成されるかを展開したもの。クラスター $ k $ ごとに、クエリベクトル $ q $ とドキュメントベクトル $ p $ のすべてのペアの内積 $\langle q, p \rangle$ に、$ \frac{1}{|P \cap \phi^{-1}(k)|} $ という重みをかけて足し合わせています。

この重み $ \frac{1}{|P \cap \phi^{-1}(k)|} $ が鍵です。これは、クラスター $ k $ 内のドキュメントベクトルの数の逆数で、**ドキュメント側の重心 $\vec{p}^{(k)}$ を計算したときにすでに含まれている正規化**を明示的に書き出したものです。つまり、この式は、

> 「あるクエリベクトル $ q $ がクラスター $ k $ に属するとき、その $ q $ は、クラスター $ k $ のドキュメントの平均ベクトルと内積を取る」  
> → それが、そのクエリベクトルとドキュメント全体の類似度の近似値になる

という直感的なメカニズムを、数式で厳密に表現しています。

このとき、もしクラスター $ k $ にクエリのベクトル $ q $ と、**ドキュメント中の最も似ている**ベクトル $ p^* $ が同じクラスターに含まれていれば、$ \langle q, p^* \rangle $ の値がこの和の主要な部分を占め、結果的にChamfer類似度（＝各クエリベクトルに対して、ドキュメント内で最も似ているベクトルとの最大内積の合計）に近づくわけです。

したがって、式(3)は、「**個々のトークン間の複雑な対応づけを、空間のクラスターごとに集約された平均操作で置き換えること**」によって、もともと $ O(|Q| \cdot |P|) $ の計算量が必要だったChamfer類似度を、$ O(B \cdot d) $ の内積計算だけで近似する、というMUVERAの本質を数理的に定義しているのです。これが、理論的に有効な「単一ベクトルへの還元」の中心です。


まず、$\phi^{-1}(k)$ の意味
関数 $\phi$ は「各ベクトル $p \in P$」を「クラスター $k \in \{1, 2, \dots, B\}$」に割り当てるハッシュ関数です。
つまり、$\phi(p) = k$ は「ベクトル $p$ はクラスター $k$ に割り当てられた」という意味です。
では、$\phi^{-1}(k)$ とは？
これは、**逆像（inverse image）**と呼ばれる数学的概念で、

$\phi^{-1}(k) = \{ p \in P \mid \phi(p) = k \}$

という意味です。
つまり、「その関数 $\phi$ の出力が $k$ になるような、すべての入力 $p$ の集合」です。
$\phi$ は「1対複数」の関数（複数のベクトルが同じクラスターに割り当てられるので、全単射ではない）なので、本当の意味での逆関数ではありません。
しかし、集合論では、逆像 $\phi^{-1}(k)$ は、どんな関数でも定義可能です。これは、**「k というクラスターに飛ぶすべてのベクトルの集まり」**を表す標準的な記号なのです。

次に、$P \cap \phi^{-1}(k)$
集合 $P$ は、ドキュメントのすべてのベクトル（トークン埋め込み）の集合です。
$\phi^{-1}(k)$ も、実は $P$ の部分集合です（なぜなら $\phi$ は $P$ 上で定義されているから）。
だから、$P \cap \phi^{-1}(k)$ は、
**「P の中で、クラスター k に割り当てられたベクトル全部」**という意味で、
実は $\phi^{-1}(k)$ と同じです。
ここに $P \cap$ を書いているのは、数学的に厳密に書くためです。
たとえば $\phi$ が、$P$ のみでなく他の集合も定義域に含む場合を想定するとき、この交差（intersection）で「P に属するもののみを抽出」する意味があります。
ですが、この論文ではすでに $\phi$ が $P$ 上で定義されているので、$P \cap \phi^{-1}(k)$ は単に $\phi^{-1}(k)$ と同じです。
つまり、

$P \cap \phi^{-1}(k) = \{ p \in P \mid \phi(p) = k \}$


最後に、「割るとなぜ重心になる？」という疑問
式で $\vec{p}^{(k)}$ を次のように定義しています：
$$
\vec{p}^{(k)} = \frac{1}{|P \cap \phi^{-1}(k)|} \sum_{\substack{p \in P \\ \phi(p) = k}} p
$$
この分母 $|P \cap \phi^{-1}(k)|$ は、クラスター $k$ に所属するドキュメントベクトルの個数です。
たとえば、クラスター k に 5 個のドキュメントベクトルが集まったとします。
その 5 つのベクトルを足し合わせて、5 で割れば、**その5つのベクトルの平均（重心、centroid）**になります。
だから、「割る」→ 「平均を取る」→ 「重心になる」
これは単なる定義です。数学的に、集合内の要素の和をその個数で割ったものが「重心」です。それは一次元でも多次元でも変わりません。
（たとえば、座標 (1,2), (3,4), (2,3) の重心は $(\frac{1+3+2}{3}, \frac{2+4+3}{3}) = (2,3)$）
MUVERA がなぜ「和」ではなく「平均」を使うかというと、先に述べたように——
もし和を使えば、クラスターにベクトルがたくさん集まれば集まるほど、そのクラスターの重みが大きくなりすぎ、類似度の見積もりが偏って過大評価されてしまいます。
「平均」を使うことで、「クラスターに入っているベクトルの数」に依存しない、バランスの取れた代表値になり、Chamfer類似度の正確な近似が可能になるのです。

上により

この操作により、各クラスター $k$ に1つずつベクトルブロックができます。$B$ 個のクラスターがあれば、結果として $\vec{q} = (\vec{q}^{(1)}, \vec{q}^{(2)}, \dots, \vec{q}^{(B)})$ のような、$B \cdot d$ 次元のベクトルが生成されます。

(3)式以降

結果として、ベクトル $\vec{q}$ および $\vec{p}$ の次元は $dB$ になります。$d$ への依存性を減らすために、各ブロック $\vec{q}^{(k)}, \vec{p}^{(k)}$ にランダムな線形射影 $\psi : \mathbb{R}^d \to \mathbb{R}^{d_{\text{proj}}}$ を適用できます。ここで $d_{\text{proj}} < d$ とし、$\psi(\mathbf{x}) = \frac{1}{\sqrt{d_{\text{proj}}}} S \mathbf{x}$ と定義します。ただし、$S \in \mathbb{R}^{d_{\text{proj}} \times d}$ はすべてのエントリが均一に分布した $\pm 1$ をとるランダム行列です。これにより、$\vec{q}^{(k),\psi} = \psi(\vec{q}^{(k)})$ および $\vec{p}^{(k),\psi} = \psi(\vec{p}^{(k)})$ を定義し、内部射影付きのFDEを $\vec{q}^\psi = (\vec{q}^{(1),\psi}, \dots, \vec{q}^{(B),\psi})$ および $\vec{p}^\psi = (\vec{p}^{(1),\psi}, \dots, \vec{p}^{(B),\psi})$ として定義します。$d = d_{\text{proj}}$ の場合、$\psi$ は恒等写像として定義され、このとき $\vec{q}^\psi, \vec{p}^\psi$ はそれぞれ $\vec{q}, \vec{p}$ と一致します。式(3)の近似精度を高めるために、異なるランダムな分割 $\varphi_1, \dots, \varphi_{R_{\text{reps}}}$ および射影 $\psi_1, \dots, \psi_{R_{\text{reps}}}$ を用いて、上記のプロセスを $R_{\text{reps}} \geq 1$ 回独立に繰り返します。$i$ 番目の繰り返しで得られるベクトルを $\vec{q}^{i,\psi}, \vec{p}^{i,\psi}$ と表記します。最後に、これら $R_{\text{reps}}$ 個のベクトルを連結し、最終的なFDEを $F_q(Q) = (\vec{q}^{1,\psi}, \dots, \vec{q}^{R_{\text{reps}},\psi})$ および $F_{\text{doc}}(P) = (\vec{p}^{1,\psi}, \dots, \vec{p}^{R_{\text{reps}},\psi})$ として定義します。このFDEマッピングは、3つのパラメータ $(B, d_{\text{proj}}, R_{\text{reps}})$ によって完全に指定され、最終的な次元は $d_{\text{FDE}} = B \cdot d_{\text{proj}} \cdot R_{\text{reps}}$ となります。

↓ わかりやすく

3. 内部射影（$\psi$ の適用）
$\vec{q}^{(k)}$ と $\vec{p}^{(k)}$ は $d$ 次元ですが、$B$ 個のクラスタすべてを連結すると、全体の次元は $B \cdot d$ となり、非常に大きくなります。
これを軽減するために、ランダム線形射影 $\psi : \mathbb{R}^d \to \mathbb{R}^{d_{\text{proj}}}$（$d_{\text{proj}} < d$）を各クラスタベクトルに適用します。
射影は次のように行います：
$$
\psi(x) = \frac{1}{\sqrt{d_{\text{proj}}}} S x
$$
ここで、$S \in \mathbb{R}^{d_{\text{proj}} \times d}$ は、各エントリが $\pm 1$ を等確率で取るランダム行列です。この射影は、Johnson-Lindenstrauss の補題に基づき、ベクトルの内積を高確率でほぼ保存する性質を持っています。つまり、以下の性質が成り立ちます：
$$
\langle \psi(\vec{q}^{(k)}), \psi(\vec{p}^{(k)}) \rangle \approx \langle \vec{q}^{(k)}, \vec{p}^{(k)} \rangle
$$
射影後、それぞれのクラスタベクトルは $d_{\text{proj}}$ 次元となり、結合したFDE全体の次元は $B \cdot d_{\text{proj}}$ になります。

- さらにその後

この選択部分は、MUVERAがどのようにして複数のベクトル（multi-vector）の類似性を、単一のベクトル（single-vector）の内積で近似するか、その核心的な仕組みを説明しています。特に、「繰り返し」（repetition）というアイデアが、近似の精度を飛躍的に高める鍵になっています。

---

MUVERAの基本的なアイデアは、クエリ $ Q = \{q_1, q_2, \dots, q_m\} $ とドキュメント $ P = \{p_1, p_2, \dots, p_n\} $ という各々のベクトルの集合を、一つの固定次元ベクトル（Fixed Dimensional Encoding, FDE）に変換するということです。このFDE同士の内積 $ \langle \vec{q}, \vec{p} \rangle $ が、もとの Chamfer 类似度 $ \text{CHAMFER}(Q, P) = \sum_{q \in Q} \max_{p \in P} \langle q, p \rangle $ をよく近似できれば、従来の複雑で高コストなマルチベクトル検索を、既存の最適化された単一ベクトル検索（MIPS）で代替できるという夢のような構想です。

しかし、一回の変換だけでは、この近似は不十分です。なぜなら、ランダムなクラスタリング（$ \phi $）によって、あるクエリベクトル $ q $ とその最も類似するドキュメントベクトル $ p^* $ が、偶然異なるクラスタに割り当てられてしまう可能性があるからです。このようなマッチングの失敗が積み重なると、内積 $ \langle \vec{q}, \vec{p} \rangle $ は真の Chamfer 類似度から大きくずれてしまいます。

これを解決するために、MUVERAは**繰り返し処理**（repetition）を取り入れています。具体的には、同じ変換プロセスを $ R_{\text{reps}} $ 回、**独立に**繰り返すんです。それぞれの繰り返し $ i = 1, \dots, R_{\text{reps}} $ で、次のような新規の変換が行われます：

- 新しいランダムなクラスタ分割関数 $ \phi_i : \mathbb{R}^d \to [B] $ を生成します。これは、例えば SimHash などのLocality-Sensitive Hashing（LSH）を使って、空間をランダムに $ B $ 個の領域に分けるものです。
- 新しい射影行列 $ \psi_i : \mathbb{R}^d \to \mathbb{R}^{d_{\text{proj}}} $ （ランダムな $ \pm 1 $ 要素を持つ行列）を生成し、各クラスタの和ベクトルを低次元に圧縮します。
- それに基づいて、クエリ $ Q $ とドキュメント $ P $ の新しいFDEベクトル $ \vec{q}^{i,\psi} $ と $ \vec{p}^{i,\psi} $ を計算します。

このとき、1回目は：

$$
\vec{q}^{1,\psi} = \left( \psi_1\left( \sum_{\substack{q \in Q \\ \phi_1(q) = 1}} q \right),\ \psi_1\left( \sum_{\substack{q \in Q \\ \phi_1(q) = 2}} q \right),\ \dots,\ \psi_1\left( \sum_{\substack{q \in Q \\ \phi_1(q) = B}} q \right) \right)
$$

そして2回目、3回目と、それぞれ新しい $ \phi_i $ と $ \psi_i $ の下で同様の操作を繰り返します。

最終的に、この $ R_{\text{reps}} $ 個のFDEベクトルを**並べて連結**して、最終的なFDEを構成します：

$$
F_q(Q) = \left( \vec{q}^{1,\psi}, \vec{q}^{2,\psi}, \dots, \vec{q}^{R_{\text{reps}},\psi} \right)
$$

$$
F_{\text{doc}}(P) = \left( \vec{p}^{1,\psi}, \vec{p}^{2,\psi}, \dots, \vec{p}^{R_{\text{reps}},\psi} \right)
$$

このような連結されたFDEの内積は、次のようになります：

$$
\langle F_q(Q), F_{\text{doc}}(P) \rangle = \sum_{i=1}^{R_{\text{reps}}} \langle \vec{q}^{i,\psi}, \vec{p}^{i,\psi} \rangle
$$

ここで、それぞれの $ \langle \vec{q}^{i,\psi}, \vec{p}^{i,\psi} \rangle $ は、ランダムな $ \phi_i $ と $ \psi_i $ の下での Chamfer 類似度の「無偏推定量」です。つまり、一回の試行では誤差が大きいかもしれませんが、平均を取れば真の値に収束するのです（中心極限定理のような性質）。

この繰り返しが何をもたらすかというと、**誤差が平均化され、近似精度が保証付きで向上する**ことです。たとえば、$ R_{\text{reps}} = 1 $ だと、ある $ q $ と $ p^* $ のマッチングが失敗して内積が大きく低く推定され、検索性能が落ちる可能性があります。しかし、$ R_{\text{reps}} = 40 $ も繰り返すと、少なくとも何回かはその $ q $ と $ p^* $ が同じクラスタに落ち、そのたびに正しい類似度の信号が追加されるのです。最終的な内積は、その「成功した」回の寄与が支配的になります。

数学者的には、この繰り返しによって、誤差の標準偏差が $ 1/\sqrt{R_{\text{reps}}} $ で減少する（確率的な減衰）ことが理論的に保証されています。論文の定理 2.2 では、たとえば $ R_{\text{reps}} = O\left( \frac{1}{\varepsilon^2} \log n \right) $ と設定することで、$ \varepsilon $ の誤差で真の最近傍を高確率で見つけられることを証明しています。つまり、$ R_{\text{reps}} $ を適切に大きくすれば、精度は自由に調整可能になるんです。

このように、MUVERAの「繰り返し」は、単なるハックではなく、**確率的近似の理論的根拠に基づいた設計**です。一回の変換では不安定でも、繰り返すことでノイズがキャンセルされ、安定して信頼できる類似度スコアが得られる——これこそが、MUVERAが既存のマルチステージ手法（PLAID）よりも単純で、かつ性能が優れている理由の一つなのです。

- 内部射影について

これは、**「内部射影（$\psi$ の適用）」** と呼ばれる手法について説明しています。

要するに、**クラスタベクトル（$\vec{q}^{(k)}$ や $\vec{p}^{(k)}$）の次元が高すぎて扱いにくい**ため、**ランダムな方法で次元を削減**している、ということです。

---

## 💡 要点の解説

### 1. そもそもの問題点
* 個々のクラスタベクトル $\vec{q}^{(k)}$ と $\vec{p}^{(k)}$ の次元は $d$ です。
* クラスタの総数が $B$ 個あるため、これらをすべて結合すると、全体の次元は $B \cdot d$ となり、**非常に大きな次元**（高次元）になってしまいます。
* 高次元だと、計算量が増えたり、データが疎になりやすくなったり（次元の呪い）と、処理が難しくなります。

### 2. 解決策：ランダム線形射影 $\psi$ の適用
* この高すぎる次元を**軽減**するために、**ランダム線形射影 $\psi$** という操作を各クラスタベクトルに適用します。
* 射影 $\psi$ は、元の $d$ 次元のベクトルを、より低い $d_{\text{proj}}$ 次元のベクトルに変換します（$d_{\text{proj}} < d$）。

### 3. 射影の仕組み
* 射影は次の式で行われます:
    $$
    \psi(x) = \frac{1}{\sqrt{d_{\text{proj}}}} S x
    $$
* ここで、$S$ は**ランダム行列**です。この行列の各要素は、**+1 または -1 を等確率で取る**という特殊な構造をしています。
* $\frac{1}{\sqrt{d_{\text{proj}}}}$ は、ベクトルの長さを調整するための**正規化係数**です。

### 4. なぜこの方法を使うのか？
* この手法は**Johnson-Lindenstrauss (JL) の補題**という数学的な定理に基づいており、最大のメリットは以下の点です:
    * **ベクトルの内積（類似度）を、次元削減後も高確率でほぼ保存できる**、という性質があります。
    * 式でいうと、次元削減後の内積 $\langle \psi(\vec{q}^{(k)}), \psi(\vec{p}^{(k)}) \rangle$ が、元の内積 $\langle \vec{q}^{(k)}, \vec{p}^{(k)} \rangle$ に近い値になります。
    * これにより、情報を失うことなく、効率的に次元を下げることができます。

### 5. 結果
* 射影後、個々のクラスタベクトルは $d_{\text{proj}}$ 次元になります。
* 結合した全体の次元は $B \cdot d_{\text{proj}}$ となり、**元の $B \cdot d$ よりも大幅に小さく**なります。

---

**一言でまとめると**：「計算効率を上げるため、ベクトルの重要な性質（内積）をほとんど変えずに、ランダムな行列を使ってベクトルの次元を低くしました。」という工程の説明です。

この説明は、**特徴量の次元削減**や**データ圧縮**といった文脈でよく用いられる技術です。




- 以下シングルベクトルになってるか？

はい、**完全にシングルベクトルになっています**。

MUVERAの核心的な成果は、複数のベクトル（たとえば、クエリやドキュメントの各トークンごとの埋め込み）という「集合」を、**たった一つの固定次元のベクトル**——つまり「シングルベクトル」——に圧縮することです。

あなたが引用した部分で言っている：

$$
F_q(Q) = \left( \vec{q}^{1,\psi}, \vec{q}^{2,\psi}, \dots, \vec{q}^{R_{\text{reps}},\psi} \right)
$$

これは、複数のベクトルを「連結」しているように見えますが、**連結した結果は、ただ一つの長いベクトル**です。たとえば、もし各 $ \vec{q}^{i,\psi} $ が 1000 次元で、$ R_{\text{reps}} = 40 $ なら、$ F_q(Q) $ は $ 40 \times 1000 = 40{,}000 $ 次元の**一つのベクトル**になります。これは、元のクエリが 128 個のトークンベクトルを持っているとか、ドキュメントが 500 個のトークンベクトルを持っているという複雑さとは完全に切り離されています。

つまり、**入力がいくつのベクトルでも、出力は必ず一つのベクトル**。それがMUVERAの最大の利点です。

なぜこれが革命的なのかというと、これまでのマルチベクトル検索（たとえばPLAID）は、クエリの各トークンに対して、ドキュメントのすべてのトークンと「個別に」類似度を計算する必要がありました。それは、1つのクエリに対して何万回も検索を発行するようなもので、計算が膨大で、メモリも大量に使います。

MUVERAはこうした複雑さを**一旦すべて削ぎ落とします**。クエリ $ Q $ → そのFDE $ \vec{q} $（1つのベクトル）、ドキュメント $ P $ → そのFDE $ \vec{p} $（1つのベクトル）。あとは、ただそれらの内積 $ \langle \vec{q}, \vec{p} \rangle $ を計算するだけ。これは、**最新のMIPSソルバー**（DiskANN など）で、数ミリ秒で何百万・何千万ものドキュメントと同時に比較できるレベルの速さです。

つまり、MUVERAは「マルチベクトルの情報」を、**シングルベクトルの形で、情報量をほとんど減らさずに圧縮**したのです。そして、そのシングルベクトル同士の内積が、もとの複雑な Chamfer 類似度を理論的に保証された精度で近似する。だからこそ、一番単純なやり方で、一番高い性能と速度を実現できたんです。

この“シングルベクトル化”こそが、MUVERAの真骨頂です。


- simhash

この論文で提案されている**空間分割関数 $\phi$** の選択は、複数のベクトル（トークン埋め込み）の類似性を単一のベクトルに圧縮するための鍵となる部分です。特に、**近いベクトル同士は同じクラスタに属するように**する性質（局所性保証）が求められます。これにより、非線形な Chamfer 相似度を、内積として近似できる固定次元符号（FDE）が実現されます。

---

### **SimHash の仕組み**

SimHash は、ベクトル空間 $\mathbb{R}^d$ を $2^{k_{\text{sim}}}$ 個の領域に分割するための手法で、**ランダムな超平面**を使って空間を切断します。このとき、各ベクトル $x \in \mathbb{R}^d$ に対して、$k_{\text{sim}}$ 個のランダムなガウスベクトル $g_1, \dots, g_{k_{\text{sim}}} \in \mathbb{R}^d$ を事前に生成します。そして、$x$ がそれぞれの超平面 $g_i$ のどちら側にあるかで、$k_{\text{sim}}$ 個のバイナリビットを決定します：

$$
\phi(x) = \left( \mathbf{1}(\langle g_1, x \rangle > 0),\ \mathbf{1}(\langle g_2, x \rangle > 0),\ \dots,\ \mathbf{1}(\langle g_{k_{\text{sim}}}, x \rangle > 0) \right)
$$

ここで $\mathbf{1}(\cdot)$ は指示関数で、条件を満たせば $1$、そうでなければ $0$ を返します。このビット列を $10$ 進数に変換することで、$\phi(x)$ は $[B]$ 内の整数（$B = 2^{k_{\text{sim}}}$）となり、各ベクトルがどの「セクター」に所属するかが決まります。

重要な点は、**2つのベクトル $x, y$ の角度 $\theta(x,y)$ が小さいほど、$\phi(x) = \phi(y)$ となる確率が高い**ということです。なぜなら、$g_i \cdot x$ と $g_i \cdot y$ の符号が変わる確率は、$\theta(x,y)/\pi$ に比例するからです。したがって、**直感的に「似たベクトル」は似たビット列にマッピングされ、同じクラスタに集まる**という性質が実現されます。

---

### **k-means クラスタリングを使った方法**

代替手段として、すべてのトークン埋め込みの集合 $\bigcup_{i=1}^n P_i$ から $k_{\text{CENTER}}$ 個のクラスタ中心（centroid）を**k-means やランダム抽出**で決定し、各ベクトル $x$ を最も近い中心に割り当てる方法があります：

$$
\phi(x) = \arg\min_{c_j \in \mathcal{C}} \|x - c_j\|_2
$$

ここで $\mathcal{C} = \{c_1, \dots, c_{k_{\text{CENTER}}}\}$ は中心の集合です。この方法は、データの構造を反映したクラスタリングを行うため、SimHash よりも**実際のデータ分布に適応的**です。例えば、質問やドキュメントの埋め込みが特定の方向に強く密集している場合、k-means はその密集領域を自然に捉え、クラスタをそれに合わせて配置できます。

しかし、この方法の欠点は、**クラスタの数 $k_{\text{CENTER}}$ を事前に固定しなければならず、データの増加に対して再学習が必要**になる点です。また、$k_{\text{CENTER}}$ が大きすぎると計算が重くなり、小さすぎると分布の細かいパターンを見逃してしまいます。

---

### **どちらを選択すべきか？**

| 手法 | メリット | 欠点 |
|------|--------|------|
| **SimHash** | 計算が高速・定数時間で適用可能・ランダム性による理論的保証| データ分布を無視するため、高密度領域と低密度領域を同じように分割してしまう |
| **k-means** | データ分布に最適化されたクラスタ形成・実績的な性能が高い | 学習が必要・クラスタ数の設定に敏感・新規データへの拡張性が低い |

この論文では、実験的に両者を比較しており、**SimHash が全体的に安定した性能を示す**と結論づけています。特に大規模な検索タスクでは、**学習不要で常に迅速に動作する SimHash の利点が圧倒的**です。一方、データが非常に制限され、しかも分布が非常に偏っている場合には、k-means によるカスタム分割が根拠を持った改善をもたらす可能性もあります。

---

### **結論：なぜこれが重要か？**

この空間分割 $\phi$ がうまく機能しないと、FDE の内積 $\langle \vec{q}, \vec{p} \rangle$ は本来の Chamfer 相似度 $ \max_{p \in P} \langle q, p \rangle $ から大きく外れてしまいます。SimHash や k-means は、この「正しく近いものを同じグループにする」という基本的な目標を追求するためのプロトコルです。  
つまり、**「近いもの同士を同じ箱に入れる」**という単純なアイデアが、複雑な多ベクトル探索を、既存の高速な単一ベクトル検索アルゴリズムの上に乗せる、画期的な橋渡しとなっているのです。


- なぜクエリ側は平均じゃなく合計で良いの？

MUVERAの設計では、クエリの固定次元エンコード（FDE）が合計（sum）で構築される一方で、ドキュメント側は平均（average）で構築される理由について、論文では直接的には明確には説明されていませんが、理論的・実践的な背景から整理できます。

この差異は、ユーザーの検索行動とリターンの性質、そして効率と精度のトレードオフの観点から必然的です。

まず、クエリは非常に短く、通常数トークンから成り立ちます（例えば「量子コンピュータの応用」）。こういう短いクエリでは、各トークンの意味的寄与が重く、どれも欠かせません。ですから、クエリのすべてのトークンエンベディングを合計することで、クエリ全体の意味的スケールを単一ベクトルに忠実に圧縮できるのです。これは「すべての要素が同等に重要」という仮定に基づいており、合計はその公平な表現になります。

一方、ドキュメントは長い。例えば、MS MARCOのd⁠avg⁠が78.8というように、1つのドキュメントに70〜80のトークンエンベディングが存在します。これらすべての単純な合計だと、ドキュメントの長さに強く依存してしまい、長文が優位になってしまいます。これは検索の公平性を損ないます。そこで、長さの偏りを防ぐために、平均を使うことで、長さごとのスケーリングを均一化しているのです。

つまり：

クエリは短い → すべてのトークンが重要 → 合計は自然で妥当（長さの問題がほぼない）
ドキュメントは長い → 長さによるバイアスを避ける必要がある → 平均を使うのが公平
さらに、この設計はMUVERAの理論的保証とも整合します。FDEの構築は、Chamfer（MaxSim）類似度を内積で近似することを目的としており、その発想は「クエリの各ベクトルに対して、ドキュメントの最も類似するベクトルを1つだけ選ぶ」というマルチベクトルのランキング戦略です。ドキュメントの平均ベクトルは、その「最も類似する部分」を代表するような中心的特徴になり、クエリの合計は、それと対をなす全体的な意図を表すことになる、という読み方ができます。


- choise of space partition

空間分割の選択において、目的とする性質とは、点同士が近いほど、より高い確率で同じクラスターに割り当てられる（すなわち $\varphi(x) = \varphi(y)$）ことです。このような性質を持つ関数は、局所感応ハッシュ関数（Locality-Sensitive Hashing, LSH）として知られています（[20]を参照）。ベクトルが正規化されている場合（ColBERTスタイルのモデルが生成するベクトルはこれに該当します）、標準的なLSHの選択肢はSimHash[8]です。具体的には、任意の $k_{\text{sim}} \geq 1$ に対して、ランダムなガウスベクトル $\mathbf{g}_1, \dots, \mathbf{g}_{k_{\text{sim}}} \in \mathbb{R}^d$ をサンプリングし、次の式で $\varphi(x)$ を定義します：
$$
\varphi(x) = \left( \mathbf{1}(\langle \mathbf{g}_1, x \rangle > 0), \dots, \mathbf{1}(\langle \mathbf{g}_{k_{\text{sim}}}, x \rangle > 0) \right),
$$
ここで、$\mathbf{1}(\cdot) \in \{0, 1\}$ は指示関数です。このビット列を10進数に変換すると、$\varphi(x)$ は $\mathbb{R}^d$ から $[B]$ への写像となり、ただし $B = 2^{k_{\text{sim}}}$ です。つまり、SimHashは $k_{\text{sim}}$ 個のランダムな半空間を引くことで $\mathbb{R}^d$ を分割し、それぞれの $2^{k_{\text{sim}}}$ 個のクラスターは、これらの半空間またはその補集合の $k_{\text{sim}}$ 重の交差によって形成されます。
別の自然なアプローチとしては、すべてのトークンエンベディングの集合 $\bigcup_{i=1}^n P_i$ から $k_{\text{CENTER}} \geq 1$ 個の中心点をランダムに、またはk-meansを用いて選択し、$\varphi(x) \in [k_{\text{CENTER}}]$ を $x$ に最も近い中心点のインデックスとして設定する方法があります。この手法については、セクション3.1でSimHashと比較しています。

- わかりやすく

この式：
$$
\varphi(x) = \left( \mathbf{1}(\langle \mathbf{g}_1, x \rangle > 0), \dots, \mathbf{1}(\langle \mathbf{g}_{k_{\text{sim}}}, x \rangle > 0) \right)
$$
は、SimHashという「局所感応ハッシュ関数」の核心部分を表していて、非常に直感的にも美しい仕組みです。

これを一言で言うと：

「あるベクトル $x$ が、ランダムに引いた $k_{\text{sim}}$ 個の平面の『どの側』にあるか」を、0と1で記録する仕組みです。


具体的に分解してみましょう。
1. $\langle \mathbf{g}_i, x \rangle$ — ベクトルの内積
これは、ベクトル $x$ と、ランダムに生成されたベクトル $\mathbf{g}_i$ の「似ている度合い」を表します。
内積が正（$> 0$）なら、$x$ と $\mathbf{g}_i$ の向きが似ている（鋭角）。
内積が負（$< 0$）なら、向きが逆（鈍角）。
2. $\mathbf{1}(\cdot)$ — 指示関数（ゼロかイチ）
これは「条件を満たしていれば1、そうでなければ0」を返す簡単な関数です：

$\mathbf{1}(\langle \mathbf{g}_i, x \rangle > 0) = 1$ ← $x$ が $\mathbf{g}_i$ の「正の側」にある → 結果は1
$\mathbf{1}(\langle \mathbf{g}_i, x \rangle > 0) = 0$ ← $x$ が $\mathbf{g}_i$ の「負の側」にある → 結果は0

3. $\mathbf{g}_1, \dots, \mathbf{g}_{k_{\text{sim}}}$ — ランダムな「切り分けの基準」
$k_{\text{sim}}$ 個のベクトル $\mathbf{g}_i$ は、それぞれが、$d$ 次元空間を半分に切る平面（超平面）を定義します。
たとえば、$d=2$（2次元平面）で $k_{\text{sim}}=3$ の場合、ランダムに3本の矢印（$\mathbf{g}_i$）を引いて、それと垂直な3本の直線で平面を6つの領域にわけます。
4. $\varphi(x)$ — 最終的な“ハッシュ値”
この結果を、すべての $i$ について並べたビット列（0と1の列）が、$\varphi(x)$ です。
例：$k_{\text{sim}} = 4$ なら、$\varphi(x) = (1, 0, 1, 1)$ のように、4桁の2進数になります。
これを10進数に変換すると、$11$ といった「番号」が得られ、これが $x$ の「クラスター番号」になります。

視覚的に想像すると…
想像してみてください。
あなたが $d=2$ の紙の上で、100個の点（ベクトル）をプロットしています。
それを、ランダムに引いた3つの直線で、8つのセクションに分割します（$2^3=8$）。
それぞれの点は、3つの直線に対して「左側か右側か」を判断され、
たとえば「右・左・右」→「101」→ クラスター5 というふうに、1つの番号に割り振られます。
ここで大事なのは：

近い点は、同じ3つの直線の同じ側にいる確率が高い
→ だから、同じ番号（クラスター）に割り当てられる

逆に、遠い点は、ある直線で「反対側」に振り分けられる確率が高いので、別々の番号になります。

なぜこれがすごいのか？

毎回、すべてのベクトルを比較する必要がなくなる → 高速化
近い点同士は基本的に同じ「番号」になる → 類似性を保持したまま圧縮
完全にランダムな平面を使っている → 計算が単純で、理論的にも安定
しかも、ハッシュの長さ $k_{\text{sim}}$ で精度を調整可能 → 使いやすい設計

この仕組みのおかげで、MUVERAは「数百のベクトルの複雑な検索」を、「1つの数値（クラスター番号）のマッチング」に変えることができ、高速・高精度を両立したのです。


- Filling Empty ClusterとFinal Projections

空クラスターの補填。FDEの近似における主な誤差の原因の一つは、クエリエンベディング $q \in Q$ に最も近いドキュメントベクトル $p \in P$ が、$q$ と異なるクラスターにマッピングされてしまう、すなわち $\varphi(p) \neq \varphi(q) = k$ となることです。この確率を減らすには、$B$ を小さくすればよいですが、その代わりに他のベクトル $p' \in P$ も同じクラスターにマッピングされやすくなり、その結果、クラスターの中心 $\vec{p}^{(k)}$ は原本の $p$ から遠ざかってしまいます。一方、$B$ をあまりにも大きくすると、$\varphi(q) = k$ となるクラスター $k$ に、$P$ のどのベクトルもマッピングされない可能性が生じます。このトレードオフを回避するために、私たちは明示的に、クラスター $k$ に $P$ のどのベクトルもマッピングされていない場合、$\vec{p}^{(k)} = \mathbf{0}$ と設定するのではなく、クラスター $k$ に最も近いベクトル $p \in P$ を $\vec{p}^{(k)}$ として設定します。その結果、$B$ を大きくするとクラスターがより小さい領域に分割されるため、推定値の精度が向上します。形式的には、$P \cap \varphi^{-1}(k) = \emptyset$ であるようなクラスター $k$ に対して、$\text{fill\_empty\_clusters}$ が有効化されていれば、$\vec{p}^{(k)} = p$ と設定します。ここで $p \in P$ は、$\varphi(p)$ と $k$ を二進列とみなしたときに、不一致なビットの数が最小となるベクトルです（同点の場合は適当に打破します）。この処理はクエリのFDEに対しては有効化しません。なぜなら、これを行うと、同じクエリエンベディング $q \in Q$ がドット積に複数回寄与してしまうためです。
最終的射影。次元削減の自然なアプローチとして、FDE全体に最終的な射影 $\psi' : \mathbb{R}^{d_{\text{FDE}}} \to \mathbb{R}^{d_{\text{final}}}$（これもランダムな $\pm 1$ 行列による乗算で実装可能）を適用し、最終的な次元を任意の $d_{\text{final}} < d_{\text{FDE}}$ に引き下げることができます。実験的に、固定次元においてこの最終射影は、1〜2％程度の小さなが無視できないリコールの改善をもたらすことが確認されています（§C.2を参照）。





## More efficient multi-vector embeddings with MUVERA

https://weaviate.io/blog/muvera
https://arxiv.org/abs/2405.19504
https://zenn.dev/kun432/scraps/6ec056b6483eac
https://research.google/blog/muvera-making-multi-vector-retrieval-as-fast-as-single-vector-search/

asbtract

```
この論文では、マルチベクターリトリーバル（multi-vector retrieval）の計算コストを劇的に削減する新たなアルゴリズム「MUVERA」が提案されています。従来のモデル（例：ColBERTやPLAID）は、クエリとドキュメントの各ターケットを複数のベクトルで表現し、それらの類似度を「Chamfer類似度」という複雑な操作で計算する必要があり、高速な検索が困難でした。MUVERAは、この複数ベクトルの類似度を、単一のベクトル（Fixed Dimensional Encoding: FDE）の内積で近似する方法を考案しました。このFDEは、空間をランダムにクラスタリングし、各クラスタ内でのベクトルの平均を用いて構築され、理論的にも高精度な近似が保証されています。実験では、MUVERAがPLAIDと同等以上のリコールを達成しながら、レイテンシーを90%削減し、検索候補の数も2～5倍減らすことに成功しました。さらに、FDEを製品量子化（Product Quantization）で32倍圧縮しても精度の損失がほとんどないため、メモリ効率も非常に高いです。この手法は、従来の複雑でチューニングが必要な多段階アルゴリズムではなく、単一のステップで高速な検索を実現するという点で革新的です。
```




## ranx
- https://zenn.dev/kun432/scraps/0f1577a6988558


## 参考ドキュメント
https://docs.weaviate.io/agents/query
https://docs.weaviate.io/agents/query/usage
https://docs.weaviate.io/agents/query/tutorial-ecommerce
https://weaviate.io/blog/weaviate-agents
